{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import verifiers as vf\n",
    "\n",
    "dataset: Dataset = load_dataset('agentlans/wikipedia-paragraphs', split='train') # type: ignore\n",
    "dataset = dataset.map(lambda x: {'question': x['text'], 'answer': x['text']}) #[::-1]})\n",
    "parser = vf.XMLParser(['think', 'answer'], answer_field=\"answer\")\n",
    "system_prompt = f\"\"\"Respond in the following format:\n",
    "{parser.get_format_str()}\n",
    "\n",
    "Summarize the given text.\"\"\"\n",
    "\n",
    "def lcs_reward_func(completion, answer, **kwargs) -> float:\n",
    "    \"\"\"\n",
    "    LCS ratio of the prompt and the parsed completion.    \n",
    "    \"\"\"\n",
    "    def lcs_ratio(x: str, y: str) -> float:\n",
    "        \"\"\"\n",
    "        Return the longest common subsequence ratio of x and y.\n",
    "        \"\"\"\n",
    "        from difflib import SequenceMatcher\n",
    "        return SequenceMatcher(None, x, y).ratio()\n",
    "    response = parser.parse_answer(completion) or ''\n",
    "    return lcs_ratio(response, answer)\n",
    "\n",
    "rubric = vf.Rubric(funcs=[\n",
    "\tlcs_reward_func,\n",
    "\tparser.get_format_reward_func(),\n",
    "], weights=[1.0, 0.2])\n",
    "\n",
    "vf_env = vf.SingleTurnEnv(\n",
    "    dataset=dataset,\n",
    "    system_prompt=system_prompt,\n",
    "    parser=parser,\n",
    "    rubric=rubric\n",
    ")\n",
    "\n",
    "# collect V3/R1 rollouts from API\n",
    "import os\n",
    "from openai import OpenAI\n",
    "base_url = \"http://0.0.0.0:8000/v1\"\n",
    "client = OpenAI(base_url=base_url, api_key=\"local\")\n",
    "\n",
    "# columns = ['prompt', 'completion', 'answer', 'reward']\n",
    "# use deepseek-chat for multiturn rollouts (V3-0324)\n",
    "model = \"Qwen/Qwen2.5-14B-Instruct\"\n",
    "#model = \"willcb/Qwen2.5-7B-Reverse-SFT\"\n",
    "results = vf_env.eval_api(client, model=model, num_samples=10)\n",
    "\n",
    "# pretty-print results \n",
    "print(sum(results['reward']) / len(results['reward'])) # type: ignore\n",
    "for k in results.keys():\n",
    "    if 'reward' in k:\n",
    "        print(k, sum(results[k]) / len(results[k])) # type: ignore\n",
    "\n",
    "# filter to top half of rows by rewards\n",
    "# dataset_r1 = dataset_r1.sort(\"reward\", reverse=True).select(range(len(dataset_r1) // 2))\n",
    "# # # save to hub\n",
    "# dataset_r1.push_to_hub(\"V3-reverse-wikipedia-paragraphs-test\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
